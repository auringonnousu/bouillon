{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3eiGBNhJF-6k"
      },
      "source": [
        "Correlation Table for S&P 500?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hHfO_vwvuH1a"
      },
      "source": [
        "## Stock Price prediction based on the usage of RNN | LSTM\n",
        "\n",
        "Predicting the close stock price"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OMSNt3q3CJCT",
        "outputId": "9ebef15e-0f38-4368-9a0d-d5ea6fff3849"
      },
      "outputs": [],
      "source": [
        "#!python3.9 -m pip install --upgrade mplfinance\n",
        "#!python3.9 -m pip --upgrade pandas\n",
        "# !python3.9 -m pip install pandas-datareader --upgrade\n",
        "# !python3.9 -m pip install yfinance\n",
        "# !python3.9 -m pip install fredapi"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "-_46lbpbuH1e"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2023-02-14 20:57:32.140427: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
            "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
          ]
        }
      ],
      "source": [
        "import math\n",
        "import pandas_datareader.data as web\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import datetime\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, LSTM\n",
        "import matplotlib.pyplot as plt\n",
        "# from mplfinance import candlestick_ohlc\n",
        "\n",
        "from mplfinance.original_flavor import candlestick_ohlc\n",
        "import matplotlib.dates as mdates\n",
        "plt.style.use('fivethirtyeight')\n",
        "\n",
        "from pandas_datareader import data as pdr\n",
        "import yfinance as yfin\n",
        "\n",
        "from config import fred_api\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0ndLW9REuH1g"
      },
      "source": [
        "Fill in the stock you want to crawl:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "l1ZOjYV-A628"
      },
      "outputs": [],
      "source": [
        "company = 'amc'\n",
        "provider = 'yahoo'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "rvyzB2eHuH1h"
      },
      "outputs": [],
      "source": [
        "# Get stock quote\n",
        "#start = datetime.datetime(2018-3-1) # Change Date if needed\n",
        "start = datetime.datetime(2018, 1, 1) # Change Date if needed\n",
        "\n",
        "end = datetime.datetime.now()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "5l2g-KMyWmzG"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[*********************100%***********************]  1 of 1 completed\n"
          ]
        }
      ],
      "source": [
        "# df = web.DataReader(company, provider, start, end)\n",
        "\n",
        "yfin.pdr_override()\n",
        "\n",
        "df = pdr.get_data_yahoo(company, start, end)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {},
      "outputs": [],
      "source": [
        "df = df.reset_index(level=0)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {},
      "outputs": [],
      "source": [
        "from fredapi import Fred\n",
        "fred = Fred(api_key=fred_api)\n",
        "\n",
        "# sp500 = fred.get_series('SP500')\n",
        "# gdp = fred.get_series_latest_release('GDP')\n",
        "\n",
        "# Retrieve interest rate data from FRED\n",
        "interest_rates = fred.get_series('FEDFUNDS', observation_start=start)\n",
        "empl = fred.get_series('PAYEMS', observation_start=start) # seasonally ajusted non-farm employment in thousands, All Employees, Total Nonfarm (PAYEMS)\n",
        "gdp = fred.get_series('GDPC1', observation_start=start) # Seasonally adjusted real GDP \n",
        "unemp =fred.get_series('UNRATE', observation_start=start) # seasonally ajusted unemployment rate in percent\n",
        "SP500=fred.get_series('SP500', observation_start=start)\n",
        "\n",
        "# Convert index to datetime\n",
        "interest_rates.index = pd.to_datetime(interest_rates.index)\n",
        "\n",
        "df['Date'] = pd.to_datetime(df['Date'])\n",
        "df.set_index('Date', inplace=True)\n",
        "\n",
        "df['Interest_Rate'] = interest_rates.reindex(df.index, method='nearest')\n",
        "# Compute rolling average of interest rates\n",
        "interest_rates_ma = interest_rates.rolling(window=20).mean()\n",
        "\n",
        "# Combine interest rate data with stock price data\n",
        "df['InterestRates_calc'] = interest_rates_ma.reindex(df.index, method='nearest')\n",
        "df['InterestRates'] = interest_rates_ma.reindex(df.index, method='nearest')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {},
      "outputs": [],
      "source": [
        "df['SP500'] = SP500.reindex(df.index, method='nearest')\n",
        "df['unemployment_rate'] = unemp.reindex(df.index, method='nearest')\n",
        "df['gdp'] = gdp.reindex(df.index, method='nearest')\n",
        "df['Nonfarm'] = empl.reindex(df.index, method='nearest') # Units:  Thousands of Persons, Seasonally Adjusted"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Date</th>\n",
              "      <th>Open</th>\n",
              "      <th>High</th>\n",
              "      <th>Low</th>\n",
              "      <th>Close</th>\n",
              "      <th>Adj Close</th>\n",
              "      <th>Volume</th>\n",
              "      <th>Interest_Rate</th>\n",
              "      <th>InterestRates_calc</th>\n",
              "      <th>InterestRates</th>\n",
              "      <th>SP500</th>\n",
              "      <th>unemployment_rate</th>\n",
              "      <th>gdp</th>\n",
              "      <th>Nonfarm</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>2018-01-02</td>\n",
              "      <td>15.20</td>\n",
              "      <td>15.65</td>\n",
              "      <td>14.90</td>\n",
              "      <td>15.400</td>\n",
              "      <td>12.549153</td>\n",
              "      <td>2257200</td>\n",
              "      <td>1.41</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>2695.81</td>\n",
              "      <td>4.0</td>\n",
              "      <td>18437.127</td>\n",
              "      <td>147670.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2018-01-03</td>\n",
              "      <td>15.45</td>\n",
              "      <td>15.50</td>\n",
              "      <td>14.90</td>\n",
              "      <td>15.000</td>\n",
              "      <td>12.223199</td>\n",
              "      <td>1631000</td>\n",
              "      <td>1.41</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>2713.06</td>\n",
              "      <td>4.0</td>\n",
              "      <td>18437.127</td>\n",
              "      <td>147670.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2018-01-04</td>\n",
              "      <td>15.00</td>\n",
              "      <td>15.10</td>\n",
              "      <td>14.35</td>\n",
              "      <td>14.450</td>\n",
              "      <td>11.775018</td>\n",
              "      <td>2141000</td>\n",
              "      <td>1.41</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>2723.99</td>\n",
              "      <td>4.0</td>\n",
              "      <td>18437.127</td>\n",
              "      <td>147670.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>2018-01-05</td>\n",
              "      <td>14.50</td>\n",
              "      <td>14.56</td>\n",
              "      <td>14.05</td>\n",
              "      <td>14.100</td>\n",
              "      <td>11.489810</td>\n",
              "      <td>2009000</td>\n",
              "      <td>1.41</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>2743.15</td>\n",
              "      <td>4.0</td>\n",
              "      <td>18437.127</td>\n",
              "      <td>147670.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>2018-01-08</td>\n",
              "      <td>14.30</td>\n",
              "      <td>14.35</td>\n",
              "      <td>13.65</td>\n",
              "      <td>13.800</td>\n",
              "      <td>11.245344</td>\n",
              "      <td>2347400</td>\n",
              "      <td>1.41</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>2747.71</td>\n",
              "      <td>4.0</td>\n",
              "      <td>18437.127</td>\n",
              "      <td>147670.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1284</th>\n",
              "      <td>2023-02-08</td>\n",
              "      <td>6.12</td>\n",
              "      <td>6.13</td>\n",
              "      <td>5.61</td>\n",
              "      <td>5.720</td>\n",
              "      <td>5.720000</td>\n",
              "      <td>31424400</td>\n",
              "      <td>4.33</td>\n",
              "      <td>1.256</td>\n",
              "      <td>1.256</td>\n",
              "      <td>4117.86</td>\n",
              "      <td>3.4</td>\n",
              "      <td>20198.091</td>\n",
              "      <td>155073.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1285</th>\n",
              "      <td>2023-02-09</td>\n",
              "      <td>5.87</td>\n",
              "      <td>5.88</td>\n",
              "      <td>5.14</td>\n",
              "      <td>5.360</td>\n",
              "      <td>5.360000</td>\n",
              "      <td>29113300</td>\n",
              "      <td>4.33</td>\n",
              "      <td>1.256</td>\n",
              "      <td>1.256</td>\n",
              "      <td>4081.50</td>\n",
              "      <td>3.4</td>\n",
              "      <td>20198.091</td>\n",
              "      <td>155073.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1286</th>\n",
              "      <td>2023-02-10</td>\n",
              "      <td>5.21</td>\n",
              "      <td>5.21</td>\n",
              "      <td>4.64</td>\n",
              "      <td>4.900</td>\n",
              "      <td>4.900000</td>\n",
              "      <td>38589100</td>\n",
              "      <td>4.33</td>\n",
              "      <td>1.256</td>\n",
              "      <td>1.256</td>\n",
              "      <td>4090.46</td>\n",
              "      <td>3.4</td>\n",
              "      <td>20198.091</td>\n",
              "      <td>155073.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1287</th>\n",
              "      <td>2023-02-13</td>\n",
              "      <td>4.75</td>\n",
              "      <td>4.91</td>\n",
              "      <td>4.58</td>\n",
              "      <td>4.680</td>\n",
              "      <td>4.680000</td>\n",
              "      <td>26219400</td>\n",
              "      <td>4.33</td>\n",
              "      <td>1.256</td>\n",
              "      <td>1.256</td>\n",
              "      <td>4137.29</td>\n",
              "      <td>3.4</td>\n",
              "      <td>20198.091</td>\n",
              "      <td>155073.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1288</th>\n",
              "      <td>2023-02-14</td>\n",
              "      <td>4.55</td>\n",
              "      <td>4.62</td>\n",
              "      <td>4.39</td>\n",
              "      <td>4.545</td>\n",
              "      <td>4.545000</td>\n",
              "      <td>28225338</td>\n",
              "      <td>4.33</td>\n",
              "      <td>1.256</td>\n",
              "      <td>1.256</td>\n",
              "      <td>4137.29</td>\n",
              "      <td>3.4</td>\n",
              "      <td>20198.091</td>\n",
              "      <td>155073.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>1289 rows Ã— 14 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "           Date   Open   High    Low   Close  Adj Close    Volume  \\\n",
              "0    2018-01-02  15.20  15.65  14.90  15.400  12.549153   2257200   \n",
              "1    2018-01-03  15.45  15.50  14.90  15.000  12.223199   1631000   \n",
              "2    2018-01-04  15.00  15.10  14.35  14.450  11.775018   2141000   \n",
              "3    2018-01-05  14.50  14.56  14.05  14.100  11.489810   2009000   \n",
              "4    2018-01-08  14.30  14.35  13.65  13.800  11.245344   2347400   \n",
              "...         ...    ...    ...    ...     ...        ...       ...   \n",
              "1284 2023-02-08   6.12   6.13   5.61   5.720   5.720000  31424400   \n",
              "1285 2023-02-09   5.87   5.88   5.14   5.360   5.360000  29113300   \n",
              "1286 2023-02-10   5.21   5.21   4.64   4.900   4.900000  38589100   \n",
              "1287 2023-02-13   4.75   4.91   4.58   4.680   4.680000  26219400   \n",
              "1288 2023-02-14   4.55   4.62   4.39   4.545   4.545000  28225338   \n",
              "\n",
              "      Interest_Rate  InterestRates_calc  InterestRates    SP500  \\\n",
              "0              1.41                 NaN            NaN  2695.81   \n",
              "1              1.41                 NaN            NaN  2713.06   \n",
              "2              1.41                 NaN            NaN  2723.99   \n",
              "3              1.41                 NaN            NaN  2743.15   \n",
              "4              1.41                 NaN            NaN  2747.71   \n",
              "...             ...                 ...            ...      ...   \n",
              "1284           4.33               1.256          1.256  4117.86   \n",
              "1285           4.33               1.256          1.256  4081.50   \n",
              "1286           4.33               1.256          1.256  4090.46   \n",
              "1287           4.33               1.256          1.256  4137.29   \n",
              "1288           4.33               1.256          1.256  4137.29   \n",
              "\n",
              "      unemployment_rate        gdp   Nonfarm  \n",
              "0                   4.0  18437.127  147670.0  \n",
              "1                   4.0  18437.127  147670.0  \n",
              "2                   4.0  18437.127  147670.0  \n",
              "3                   4.0  18437.127  147670.0  \n",
              "4                   4.0  18437.127  147670.0  \n",
              "...                 ...        ...       ...  \n",
              "1284                3.4  20198.091  155073.0  \n",
              "1285                3.4  20198.091  155073.0  \n",
              "1286                3.4  20198.091  155073.0  \n",
              "1287                3.4  20198.091  155073.0  \n",
              "1288                3.4  20198.091  155073.0  \n",
              "\n",
              "[1289 rows x 14 columns]"
            ]
          },
          "execution_count": 8,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df = df.reset_index(level=0)\n",
        "df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "df['70ma'] = df['Adj Close'].rolling(window=70).mean()\n",
        "df['20ma_adj'] = df['Adj Close'].rolling(window=20).mean()\n",
        "df.dropna(inplace=True)\n",
        "\n",
        "# Calculate daily price change\n",
        "df['price_change'] = df['High'] - df['Low']\n",
        "\n",
        "# Calculate 20-day moving average\n",
        "df['20ma_close'] = df['Close'].rolling(window=20).mean()\n",
        "\n",
        "# Calculate Bollinger Bands\n",
        "df['std'] = df['Close'].rolling(window=20).std()\n",
        "df['upper_band'] = df['20ma_close'] + 2 * df['std']\n",
        "df['lower_band'] = df['20ma_close'] - 2 * df['std']\n",
        "\n",
        "df['upper_band'] = df['20ma_adj'] + 2 * df['std']\n",
        "df['lower_band'] = df['20ma_adj'] - 2 * df['std']\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oCO5b8mmuH1i",
        "outputId": "b6d7c38a-41e6-4b86-94b1-bbe0383c4b58"
      },
      "outputs": [],
      "source": [
        "df.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 238
        },
        "id": "BUX_a3P97-8H",
        "outputId": "9b0f660b-d48b-4675-dc1a-e541a089f97c"
      },
      "outputs": [],
      "source": [
        "df.tail()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Wk-HxNrfAmkd"
      },
      "outputs": [],
      "source": [
        "df_ohlc = df['Adj Close'].resample('10D').ohlc() # open high low close\n",
        "df_ohlc.dropna(inplace=True)\n",
        "df_vol = df['Volume'].resample('10D').sum()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 238
        },
        "id": "24QqRSEcBAto",
        "outputId": "ef92d5f2-58e4-4c78-8e23-6e5ffee1495a"
      },
      "outputs": [],
      "source": [
        "df_ohlc.tail(5)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4RlzYmTJBv48"
      },
      "outputs": [],
      "source": [
        "df_ohlc.reset_index(inplace=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fmdNUg_gDL3Y"
      },
      "outputs": [],
      "source": [
        "df_ohlc['Date'] = df_ohlc['Date'].map(mdates.date2num)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 300
        },
        "id": "39eNstMFDeez",
        "outputId": "a9b5632c-0b7e-4490-c3fd-1ead2374f92f"
      },
      "outputs": [],
      "source": [
        "ax1 = plt.subplot2grid((6,1), (0,0), rowspan = 5, colspan = 1)\n",
        "ax2 = plt.subplot2grid((6,1), (5,0), rowspan = 1, colspan = 1, sharex=ax1)\n",
        "ax2.ticklabel_format(style='plain')\n",
        "\n",
        "ax1.xaxis_date()\n",
        "candlestick_ohlc(ax1, df_ohlc.values, width=2, colorup='g')\n",
        "ax2.fill_between(df_vol.index.map(mdates.date2num), df_vol.values,0)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xGQJ5s84uH1i"
      },
      "source": [
        "## Train the model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 143
        },
        "id": "13-itlr891gX",
        "outputId": "906a6292-5229-4ac6-dd7e-ba2008ded234"
      },
      "outputs": [],
      "source": [
        "df.head(2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "df.columns"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "W3wiAi6huH1j",
        "outputId": "855a2bcb-3f22-40f4-df96-29265b92a096"
      },
      "outputs": [],
      "source": [
        "# Create new df w/ \"Close\" col\n",
        "\n",
        "df2 = df.filter(['Adj Close'])\n",
        "# convert to numpy array\n",
        "dataset = df2.values\n",
        "\n",
        "# Get no of rows to train the (LSTM) model on\n",
        "# train it on 80 % of the data \n",
        "training_data_len = math.ceil(len(dataset) * .8)  # math.ceil -> rounding\n",
        "training_data_len"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "pd.set_option('display.max_columns', None)\n",
        "df.tail(2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Y2JEs57kuH1j"
      },
      "outputs": [],
      "source": [
        "# Scale the data\n",
        "\n",
        "scaler = MinMaxScaler(feature_range=(0,1))  # values / features ranges 0-1 inclusive\n",
        "\n",
        "# Transformed data\n",
        "scaled_data = scaler.fit_transform(dataset.reshape(-1,1))\n",
        "# scaled_data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Yh3vaiwsuH1k"
      },
      "outputs": [],
      "source": [
        "# Create the training data set\n",
        "# Create scaled training data set\n",
        "# train_data = scaled_data[0:training_data_len, :]\n",
        "\n",
        "# Split data into x_train & y_train data set\n",
        "#reate empty lists\n",
        "x_train = [] # independent variables / features\n",
        "y_train = [] # dependent / target variable\n",
        "\n",
        "prediction_days = 180 # 60 days, modify as needed\n",
        "\n",
        "for i in range(prediction_days, len(scaled_data)):  \n",
        "    x_train.append(scaled_data[i - prediction_days:i, 0]) # never reaches i, not including i\n",
        "    y_train.append(scaled_data[i, 0])\n",
        "    # if i  <= 60:\n",
        "        #print(x_train)\n",
        "        #print()\n",
        "        #print(y_train)\n",
        "        #print()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "auWYVTmKuH1l"
      },
      "outputs": [],
      "source": [
        "# Convert x_train & y_train to numpy arrays\n",
        "x_train, y_train = np.array(x_train), np.array(y_train)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "P3XlEH5cuH1l",
        "outputId": "a88e8220-acbb-482f-cf88-0e3c569f0e81"
      },
      "outputs": [],
      "source": [
        "x_train.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vPut2MoEuH1l"
      },
      "outputs": [],
      "source": [
        "# Reshape data, LSTM expects input to be 3-dimensional\n",
        "# x_train = np.shape(x_train, (943, 60, 1))\n",
        "x_train = np.reshape(x_train, (x_train.shape[0], x_train.shape[1], 1))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vNzTPj6buH1m"
      },
      "outputs": [],
      "source": [
        "# Build LSTM model\n",
        "# This will be the model architecture\n",
        "from keras.layers import Dropout\n",
        "\n",
        "\n",
        "model = Sequential()\n",
        "model.add(LSTM(20, return_sequences=True, input_shape=(x_train.shape[1], 1)))\n",
        "#model.add(Dropout(.2))\n",
        "model.add(LSTM(20, return_sequences=True))\n",
        "#model.add(Dropout(.2))\n",
        "model.add(LSTM(20, return_sequences=False))\n",
        "#model.add(Dense(25))\n",
        "model.add(Dense(1))\n",
        "\n",
        "# the number of hidden units should be in-between the number of input units and output classes"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "S5TWITnKuH1n"
      },
      "outputs": [],
      "source": [
        "# Compile model\n",
        "model.compile(optimizer='adam', loss='mean_squared_error', metrics=['accuracy'])"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "When training a neural network for stock price prediction, mean_squared_error (MSE) is a common loss function to use. This is because the goal of stock price prediction is to minimize the difference between the predicted and actual prices.\n",
        "\n",
        "MSE measures the average squared difference between the predicted and actual values. It is a good choice for regression problems where the output values are continuous. "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ghGrZFsyuH1n",
        "outputId": "ac8a51ab-a50d-4f3c-c9cd-d90c39d14d6f"
      },
      "outputs": [],
      "source": [
        "# Train model\n",
        "#history = model.fit(x_train, y_train, epochs=10, batch_size=5) #validation_split=0.33  , verbose=0\n",
        "\n",
        "from keras.callbacks import EarlyStopping\n",
        "\n",
        "early_stop = EarlyStopping(monitor='val_loss', patience=3, verbose=1)\n",
        "\n",
        "history = model.fit(x_train, y_train, epochs=100, batch_size=5, validation_split=0.33, callbacks=[early_stop]) #verbose=0,\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        },
        "id": "ov6eDSju5fEM",
        "outputId": "cbbfc283-c826-41de-a1eb-37af67ef6748"
      },
      "outputs": [],
      "source": [
        "# Define the size of the training set\n",
        "training_data_len = int(len(dataset) * 0.67)\n",
        "\n",
        "# Create testing dataset\n",
        "test_data = scaled_data[training_data_len - prediction_days:]\n",
        "\n",
        "# Create data set x_test & y_test\n",
        "x_test = []\n",
        "y_test = dataset[training_data_len:]\n",
        "\n",
        "for i in range(prediction_days, test_data.shape[0]):\n",
        "    x_test.append(test_data[i - prediction_days:i, 0])\n",
        "\n",
        "# Convert x_test and y_test to numpy arrays\n",
        "x_test = np.array(x_test)\n",
        "y_test = np.array(y_test)\n",
        "\n",
        "# Reshape x_test to 3 dimensions for input to LSTM\n",
        "x_test = np.reshape(x_test, (x_test.shape[0], x_test.shape[1], 1))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fGCs3SN9uH1o"
      },
      "outputs": [],
      "source": [
        "# Create testing dataset\n",
        "# Create new array containing scaled values from 900 - 960\n",
        "# test_data = scaled_data[training_data_len - prediction_days: , :]\n",
        "\n",
        "# Create data set x_test & y_test\n",
        "# x_test = []\n",
        "# y_test = dataset[training_data_len: , :]  # all of values that we want the model to predict, the actual test values\n",
        "# for i in range(prediction_days, len(test_data)):\n",
        "#     x_test.append(test_data[i- prediction_days:i, 0])\n",
        "\n",
        "\n",
        "# Convert data to numpy array\n",
        "# x_test = np.array(x_test)\n",
        "\n",
        "# Reshape data -> 3-dimensional shape\n",
        "# x_test = np.reshape(x_test, (x_test.shape[0], x_test.shape[1], 1))   # x_test.shape[0] -> number of samples ; x_test.shape[1] -> number of timesteps; number of features: 1 (close price)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LF3_dbb0uH1o",
        "outputId": "6809389c-06c4-44e0-857f-45a76cdccb9e"
      },
      "outputs": [],
      "source": [
        "# Get the models predicted price values\n",
        "\n",
        "predictions = scaler.inverse_transform(model.predict(x_test))\n",
        "# we want predictions to contain same values as y_test data set\n",
        " # unscale values"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xuOVS6LIuH1p"
      },
      "outputs": [],
      "source": [
        "# Get root mean square error (RSME)\n",
        "rmse = np.sqrt(np.mean(((predictions- y_test)**2)))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "X-B66FU2uH1p",
        "outputId": "64f6b108-e14c-462b-ea1e-d9c088d1097e"
      },
      "outputs": [],
      "source": [
        "print(rmse)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gG2w92OIuH1p"
      },
      "source": [
        "### Plotting "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 558
        },
        "id": "y7s0Hq1xuH1p",
        "outputId": "a00b726f-2b55-4d56-f26c-737a606a5088"
      },
      "outputs": [],
      "source": [
        "# Plot data\n",
        "train = df[:training_data_len]\n",
        "valid = df[training_data_len:]\n",
        "valid['Predictions'] = predictions\n",
        "\n",
        "# Viz\n",
        "plt.figure(figsize=(14,6))\n",
        "plt.title('Model')\n",
        "plt.xlabel('Date', fontsize=11)\n",
        "plt.ylabel('Close Price US $', fontsize=11)\n",
        "plt.plot(train['Adj Close'])\n",
        "plt.plot(valid[['Adj Close', 'Predictions']])\n",
        "plt.legend(['Train', 'Validation', 'Predictions'], loc='lower left')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7oT8nzn5uH1q"
      },
      "source": [
        "blue = data the model was trained on\n",
        "red = actual values / actual closing price for the dates\n",
        "orange = what model predicted to be"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 238
        },
        "id": "W_o5POkJuH1q",
        "outputId": "7ee01db2-cbb6-4981-d7bd-265f6829a167"
      },
      "outputs": [],
      "source": [
        "# Show valid and predicted price\n",
        "valid.tail()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5WTZmE2_uH1q"
      },
      "source": [
        "# Predict close price for future"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kmjUi3ATuH1q",
        "outputId": "b1bd29eb-333a-4594-9388-55279801a763"
      },
      "outputs": [],
      "source": [
        "df_future = df.filter(['Close'])\n",
        "last_60_days = df_future[-prediction_days:].values\n",
        "last_60_days_scaled = scaler.transform(last_60_days)\n",
        "X_test = []\n",
        "X_test.append(last_60_days_scaled)\n",
        "X_test = np.array(X_test)\n",
        "X_test = np.reshape(X_test, (X_test.shape[0], X_test.shape[1], 1))\n",
        "\n",
        "pred_price = model.predict(X_test)\n",
        "pred_price = scaler.inverse_transform(pred_price)\n",
        "print(pred_price)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "At381F-GuH1q",
        "outputId": "f4c87f9b-c2c0-4dbb-d09b-d8b9a0e8cd5a"
      },
      "outputs": [],
      "source": [
        "df_future = df.filter(['Close'])\n",
        "last_60_days = df_future[-prediction_days-3:].values\n",
        "last_60_days_scaled = scaler.transform(last_60_days)\n",
        "X_test = []\n",
        "X_test.append(last_60_days_scaled)\n",
        "X_test = np.array(X_test)\n",
        "X_test = np.reshape(X_test, (X_test.shape[0], X_test.shape[1], 1))\n",
        "\n",
        "pred_price = model.predict(X_test)\n",
        "pred_price = scaler.inverse_transform(pred_price)\n",
        "print(f'Prediction: {pred_price}')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CSBUpO7BK5Fh"
      },
      "outputs": [],
      "source": [
        "# Prediction: [[283.78705]]\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Oc4ONsIdE4yS"
      },
      "source": [
        "--------------------\n",
        "--------------------"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "G53tq__vGYdu"
      },
      "source": [
        "## Different approach"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mvrKGBtqE6GL"
      },
      "outputs": [],
      "source": [
        "'''test_start = datetime.datetime(2022,1,1)\n",
        "test_end = datetime.datetime.now()\n",
        "\n",
        "test_df = web.DataReader(company, 'yahoo', test_start, test_end)\n",
        "actual_prices = test_df['Close'].values\n",
        "\n",
        "total_dataset = pd.concat((df['Close'], test_df['Close']), axis=0)\n",
        "\n",
        "model_inputs = total_dataset[len(total_dataset) - len(test_df) - prediction_days:].values\n",
        "model_inputs = model_inputs.reshape(-1,1)\n",
        "model_inputs = scaler.transform(model_inputs)'''"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VlqkzPf8GE3j"
      },
      "outputs": [],
      "source": [
        "# Make predictions on test data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iqxQg4xbGcoe",
        "outputId": "5d553abc-76c8-4e89-a784-861f7328548f"
      },
      "outputs": [],
      "source": [
        "x_test = []\n",
        "\n",
        "for i in range(prediction_days, len(model_inputs)):\n",
        "  x_test.append(model_inputs[i-prediction_days:i,0])\n",
        "\n",
        "x_test = np.array(x_test)\n",
        "x_test = np.reshape(x_test, (x_test.shape[0], x_test.shape[1], 1))\n",
        "\n",
        "predicted_prices = model.predict(x_test)\n",
        "predicted_prices = scaler.inverse_transform(predicted_prices)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 459
        },
        "id": "Yzg5CjTtHNTS",
        "outputId": "3660a78e-9567-4aa5-bdc2-67d1ab384166"
      },
      "outputs": [],
      "source": [
        "# Plot the test pred\n",
        "plt.figure(figsize=(14,6))\n",
        "plt.plot(actual_prices, color='black', label=f'Actual {company} Price')\n",
        "plt.plot(predicted_prices, color='green', label=f'Predicted {company} Price')\n",
        "plt.title(f'{company} Share Price')\n",
        "plt.xlabel('Time')\n",
        "plt.ylabel(f'{company} Share Price in US $')\n",
        "plt.legend(loc='upper left')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QLCdCsV1Hy_N",
        "outputId": "0f727b16-5b5d-4bd7-ccb6-5aa8629edd54"
      },
      "outputs": [],
      "source": [
        "# Predict next day\n",
        "\n",
        "real_data = [model_inputs[len(model_inputs) + 1 - prediction_days:len(model_inputs + 1), 0]]\n",
        "real_data = np.array(real_data)\n",
        "real_data = np.reshape(real_data, (real_data.shape[0], real_data.shape[1],1))\n",
        "\n",
        "# print(scaler.inverse_transform(real_data[-1]))\n",
        "\n",
        "prediction = model.predict(real_data)\n",
        "prediction = scaler.inverse_transform(prediction)\n",
        "print(f'Prediction: {prediction}')\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WYAoRIqzCISC"
      },
      "source": [
        "Different approach w/ avg of highest and lowest price\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xRBHgoz4CO3p"
      },
      "outputs": [],
      "source": [
        "# First calculate the mid prices from the highest and lowest\n",
        "high_prices = df.loc[:,'High'].as_matrix()\n",
        "low_prices = df.loc[:,'Low'].as_matrix()\n",
        "mid_prices = (high_prices+low_prices)/2.0"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "s44s2SW9CXOz"
      },
      "outputs": [],
      "source": [
        "train_data = mid_prices[:11000]\n",
        "test_data = mid_prices[11000:]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-aTmbMEECXE6"
      },
      "outputs": [],
      "source": [
        "scaler = MinMaxScaler()\n",
        "train_data = train_data.reshape(-1,1)\n",
        "test_data = test_data.reshape(-1,1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qwgjHgdlCW9o"
      },
      "outputs": [],
      "source": [
        "# Train the Scaler with training data and smooth data\n",
        "smoothing_window_size = 2500\n",
        "for di in range(0,10000,smoothing_window_size):\n",
        "    scaler.fit(train_data[di:di+smoothing_window_size,:])\n",
        "    train_data[di:di+smoothing_window_size,:] = scaler.transform(train_data[di:di+smoothing_window_size,:])\n",
        "\n",
        "# You normalize the last bit of remaining data\n",
        "scaler.fit(train_data[di+smoothing_window_size:,:])\n",
        "train_data[di+smoothing_window_size:,:] = scaler.transform(train_data[di+smoothing_window_size:,:])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rexOhbRnCW6O"
      },
      "outputs": [],
      "source": [
        "train_data = train_data.reshape(-1)\n",
        "\n",
        "# Normalize test data\n",
        "test_data = scaler.transform(test_data).reshape(-1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XEQQdggxDqyu"
      },
      "outputs": [],
      "source": [
        "EMA = 0.0\n",
        "gamma = 0.1\n",
        "for ti in range(11000):\n",
        "  EMA = gamma*train_data[ti] + (1-gamma)*EMA\n",
        "  train_data[ti] = EMA\n",
        "\n",
        "# Used for visualization and test purposes\n",
        "all_mid_data = np.concatenate([train_data,test_data],axis=0)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EEbRS9UjDquE"
      },
      "outputs": [],
      "source": [
        "window_size = 100\n",
        "N = train_data.size\n",
        "std_avg_predictions = []\n",
        "std_avg_x = []\n",
        "mse_errors = []\n",
        "\n",
        "for pred_idx in range(window_size,N):\n",
        "\n",
        "    if pred_idx >= N:\n",
        "        date = dt.datetime.strptime(k, '%Y-%m-%d').date() + dt.timedelta(days=1)\n",
        "    else:\n",
        "        date = df.loc[pred_idx,'Date']\n",
        "\n",
        "    std_avg_predictions.append(np.mean(train_data[pred_idx-window_size:pred_idx]))\n",
        "    mse_errors.append((std_avg_predictions[-1]-train_data[pred_idx])**2)\n",
        "    std_avg_x.append(date)\n",
        "\n",
        "print('MSE error for standard averaging: %.5f'%(0.5*np.mean(mse_errors)))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ry5iU0cwDqlM"
      },
      "outputs": [],
      "source": [
        "plt.figure(figsize = (18,9))\n",
        "plt.plot(range(df.shape[0]),all_mid_data,color='b',label='True')\n",
        "plt.plot(range(window_size,N),std_avg_predictions,color='orange',label='Prediction')\n",
        "#plt.xticks(range(0,df.shape[0],50),df['Date'].loc[::50],rotation=45)\n",
        "plt.xlabel('Date')\n",
        "plt.ylabel('Mid Price')\n",
        "plt.legend(fontsize=18)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HTocROMwD-G6"
      },
      "outputs": [],
      "source": [
        "window_size = 100\n",
        "N = train_data.size\n",
        "\n",
        "run_avg_predictions = []\n",
        "run_avg_x = []\n",
        "\n",
        "mse_errors = []\n",
        "\n",
        "running_mean = 0.0\n",
        "run_avg_predictions.append(running_mean)\n",
        "\n",
        "decay = 0.5\n",
        "\n",
        "for pred_idx in range(1,N):\n",
        "\n",
        "    running_mean = running_mean*decay + (1.0-decay)*train_data[pred_idx-1]\n",
        "    run_avg_predictions.append(running_mean)\n",
        "    mse_errors.append((run_avg_predictions[-1]-train_data[pred_idx])**2)\n",
        "    run_avg_x.append(date)\n",
        "\n",
        "print('MSE error for EMA averaging: %.5f'%(0.5*np.mean(mse_errors)))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gOE6qzUTD-D2"
      },
      "outputs": [],
      "source": [
        "\n",
        "plt.figure(figsize = (18,9))\n",
        "plt.plot(range(df.shape[0]),all_mid_data,color='b',label='True')\n",
        "plt.plot(range(0,N),run_avg_predictions,color='orange', label='Prediction')\n",
        "#plt.xticks(range(0,df.shape[0],50),df['Date'].loc[::50],rotation=45)\n",
        "plt.xlabel('Date')\n",
        "plt.ylabel('Mid Price')\n",
        "plt.legend(fontsize=18)\n",
        "plt.show()\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3.9.13 64-bit",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.13"
    },
    "vscode": {
      "interpreter": {
        "hash": "aee8b7b246df8f9039afb4144a1f6fd8d2ca17a180786b69acc140d282b71a49"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
